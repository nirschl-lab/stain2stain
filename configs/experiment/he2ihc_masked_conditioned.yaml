# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: paired_data_mask_he_amyloid
  - override /model: conditional_flow_matching_masked_condition
  - override /callbacks: default
  - override /trainer: default

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters
name: "Non attention fully guided mask"
WANDB_PROJECT: "positive_amyloid"
tags: ["dev"]

seed: 12345

base_lr: 1e-4
batch_size: 8

trainer:
  min_epochs: 20
  max_epochs: 50
  accelerator: "cuda"
  strategy: "ddp"
  devices: 4
  # log_every_n_steps: 2
  # limit_train_batches: 5
  # limit_val_batches: 2


model:
  optimizer:
    lr: ${base_lr}
    weight_decay: 1e-3
  log_images: True

data:
  batch_size: ${batch_size}
  num_workers: 8

logger:
  wandb:
    project: "${WANDB_PROJECT}"
    tags: ${tags}
    group: "Training"
    name: ${name}
    log_model: True
  aim:
    experiment: ""

callbacks:
  early_stopping: null
  model_checkpoint:
    dirpath: ${paths.output_dir}/checkpoints
    filename: "best-{epoch:03d}-{val/loss:.4f}"
    monitor: "val/loss"
    mode: "min"
    save_top_k: 3  # Keep top 3 best models
    save_last: True
    auto_insert_metric_name: False
    every_n_epochs: 10  # Save every 10 epochs

# callbacks:
#   early_stopping:
#     monitor: "val/loss"
#     patience: 30-50
#     mode: "min"
#     min_delta: 0.001  
#     check_on_train_epoch_end: false