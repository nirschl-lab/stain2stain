_target_: src.models.conditional_flow_matching_conditional_mask.ConditionalFlowMatchingLitModule
# Weight for auxiliary amyloid fraction loss
aux_loss_weight: 0.5

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 1e-4
  weight_decay: 0.0

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 10

net:
  _target_: torchcfm.models.unet.unet.UNetModel
  image_size: 256
  in_channels: 4  # 3 RGB + 1 condition channel
  model_channels: 128
  out_channels: 3  # 3 RGB output
  num_res_blocks: 2
  attention_resolutions: [16, 8]
  dropout: 0.1
  channel_mult: [1, 2, 2, 4]
  use_scale_shift_norm: true
  num_heads: 4
  num_head_channels: 32

# net:
#   _target_: src.models.components.unet_4to3.UNet4to3
#   image_size: 256  # Image size (assumes square images)
#   model_channels: 128  # Larger base channel count for better capacity
#   num_res_blocks: 2  # More residual blocks per level
#   attention_resolutions: [16, 8]  # Attention at 16x16 and 8x8 feature maps
#   dropout: 0.1  # Regularization
#   use_scale_shift_norm: true  # Better conditioning on time embeddings
#   num_heads: 4  # Multi-head attention
#   num_head_channels: 32  # Channels per attention head
#   channel_mult: [1, 2, 2, 4]  # Progressive channel multiplication
#   # Note: Model is configured for 4-channel input (3 RGB + 1 mask) â†’ 3-channel output (RGB)

flow_matcher:
  _target_: torchcfm.conditional_flow_matching.ConditionalFlowMatcher
  sigma: 0.0

# Optional: NeuralODE solver for inference only (not needed during training)
solver:
  _target_: torchdyn.core.NeuralODE
  _partial_: true
  solver: dopri5
  sensitivity: adjoint
  atol: 1e-4
  rtol: 1e-4

# compile model for faster training with pytorch 2.0
compile: false

log_images: true